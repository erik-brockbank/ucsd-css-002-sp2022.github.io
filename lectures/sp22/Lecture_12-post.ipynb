{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c7e6f5",
   "metadata": {},
   "source": [
    "# Lecture 12 (4/22/2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea5e3d",
   "metadata": {},
   "source": [
    "**Announcements**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac90fc6",
   "metadata": {},
   "source": [
    "*Last time we covered:*\n",
    "- Tidy data (wide / long format)\n",
    "\n",
    "**Today's agenda:**\n",
    "- Data transformations\n",
    "> Part 1: logarithmic transformations\n",
    ">\n",
    "> Part 2: z-scoring\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ebecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e3d210",
   "metadata": {},
   "source": [
    "# Part 1: log transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d491e3d3",
   "metadata": {},
   "source": [
    "## Problem: highly skewed data\n",
    "\n",
    "To get a sense of when we may need to transform our data, let's take a look at our `gapminder` dataset once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62327e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = pd.read_csv(\"https://raw.githubusercontent.com/UCSD-CSS-002/ucsd-css-002.github.io/master/datasets/gapminder.csv\")\n",
    "\n",
    "gap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7b350",
   "metadata": {},
   "source": [
    "Below we plot the distribution of *population* across the countries in this dataset for the most recent year available.\n",
    "\n",
    "What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafd813",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.histplot(\n",
    "    data = gap[gap[\"year\"] == 2007],\n",
    "    x = \"pop\",\n",
    "    bins = 60 # even with more bins the distribution is similar\n",
    ")\n",
    "g.set_xlabel(\"Population (billions)\")\n",
    "g.set_title(\"Population by country, 2007\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How skewed is the data above?\n",
    "\n",
    "gap[\"pop\"][gap[\"year\"] == 2007].mean() # ~44M\n",
    "gap[\"pop\"][gap[\"year\"] == 2007].median() # ~10.5M\n",
    "\n",
    "\n",
    "# ...big difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092e61a",
   "metadata": {},
   "source": [
    "**Why this is a problem?**\n",
    "\n",
    "Most standard statistics assumes that the variables being predicted or serving as predictors are (roughly) normally distributed. Our population data above clearly isn't!\n",
    "\n",
    "**How common is this?**\n",
    "\n",
    "The pattern above isn't unique to population. Many other common variables tend to have similarly shaped distributions. \n",
    "\n",
    "*Can you think of some others?* (hint: remember Zipf's Law back in pset 1?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c6270",
   "metadata": {},
   "source": [
    "## Solution: with skewed data, use log transform!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bcf47a",
   "metadata": {},
   "source": [
    "**What do we mean by log transforming?**\n",
    "\n",
    "We want to convert our population data to a logarithmic scale rather than a linear scale.\n",
    "\n",
    "We'll illustrate this difference below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our original graph used bins scaled at a linear interval. We're printing them below. \n",
    "\n",
    "_ = sns.histplot(\n",
    "    data = gap[gap[\"year\"] == 2007],\n",
    "    x = \"pop\",\n",
    "    bins = 20\n",
    ")\n",
    "\n",
    "# Here's our original histogram bins: note how they increase by a fixed amount\n",
    "print(\"Histogram bins: {}\".format([str(elem) for elem in plt.xticks()[0]]))\n",
    "\n",
    "# Can print each element minus the previous elemnt to show this\n",
    "# [plt.xticks()[0][i+1] - plt.xticks()[0][i] for i in range(len(plt.xticks()[0])-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: let's generate logarithmic scaled bins instead of the above.\n",
    "\n",
    "\n",
    "# Instead of increasing by a fixed amount (200k), they will increase by a fixed *multiple* (10) from 100k to 1B\n",
    "# Use `np.logspace` for this\n",
    "log_bins = np.logspace(base = 10, # specify the base (10 is default)\n",
    "                       start = 5, # specify the start, which is base**start (in this case 10e5)\n",
    "                       stop = 9, # specify the end, which is base**end (in this case 10e9)\n",
    "                       num = 10) # specify the number of bins\n",
    "\n",
    "[str(elem) for elem in log_bins]\n",
    "\n",
    "# These don't increase by a fixed amount\n",
    "# Can print each element minus the previous element as we did above to show this\n",
    "\n",
    "# [log_bins[i+1] - log_bins[i] for i in range(len(log_bins)-1)]\n",
    "\n",
    "# Instead, they increase by a fixed *multiple*\n",
    "# Can print each element in log_bins *divided by* the previous element to show this\n",
    "\n",
    "# [log_bins[i+1] / log_bins[i] for i in range(len(log_bins)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's use these logarithmic intervals as the basis for our histogram bins\n",
    "\n",
    "g = sns.histplot(\n",
    "    data = gap[gap[\"year\"] == 2007],\n",
    "    x = \"pop\",\n",
    "    bins = log_bins # This is the key change\n",
    ")\n",
    "\n",
    "# NOTE: we need to also specify that the x axis should be drawn on a logarithmic scale \n",
    "# (try graphing without this to see what happens!)\n",
    "g.set_xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c844836",
   "metadata": {},
   "source": [
    "Our data looks normally distributed when we plot it on a log scale. Woo hoo!\n",
    "\n",
    "But we haven't changed the underlying data. \n",
    "\n",
    "Let's log transform *the data itself* so its (log) values are normally distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fab429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do this, use np.log10 (np.log uses the *natural log*) \n",
    "gap['log_pop'] = np.log10(gap['pop'])\n",
    "\n",
    "gap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55d9fd",
   "metadata": {},
   "source": [
    "Now what? Let's take a look at our *log transformed* population variable.\n",
    "\n",
    "Is it normally distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.histplot(data = gap[gap['year'] == 2007], x = 'log_pop')\n",
    "g.set_xlabel(\"Log transformed population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26078eb",
   "metadata": {},
   "source": [
    "## Log transformations: Summary\n",
    "\n",
    "- Statistics and modeling solutions often assume that the underlying variables are *normally distributed*\n",
    "\n",
    "- You can count on many variables in the world being roughly normally distributed (especially with large samples!) \n",
    "\n",
    "- But certain types of data are **reliably not** normally distributed (ex. income, wealth, population, number of Twitter followers, number of Spotify streams, ...)\n",
    "\n",
    "- When your data looks like the examples above (rule of thumb: roughly exponentially distributed, or has very large right skew), it's often the case that the *logarithm* of the data *is normally distributed*.\n",
    "\n",
    "- You can check whether this is true by plotting it on a log scale as we did above. If so, consider *log transforming* your data.\n",
    "\n",
    "Note: using the log transformed values for a variable in statistics or regression changes how you interpret your results (for example, regression coefficients on a log-transformed variable X will reflect the impact of *multiplicative* changes to X on the output variable Y). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc5f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d424f093",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f6005",
   "metadata": {},
   "source": [
    "# Part 2: z-scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c370b",
   "metadata": {},
   "source": [
    "## Problem: comparing data from different distributions\n",
    "\n",
    "To get a sense of when we may need to z-score our data, let's take a look at our `pokemon` dataset once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = pd.read_csv(\"https://raw.githubusercontent.com/UCSD-CSS-002/ucsd-css-002.github.io/master/datasets/Pokemon.csv\")\n",
    "\n",
    "pk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee69fcd9",
   "metadata": {},
   "source": [
    "Let's say we want to know whether each of our pokemon is going to be better off attacking opponents, or simply outlasting them. \n",
    "\n",
    "The `Attack` variable indicates how strong they are at attacking, while `HP` indicates how long they can withstand attacks. \n",
    "\n",
    "How would we evaluate which of these is stronger for each pokemon?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3915a",
   "metadata": {},
   "source": [
    "**Strategy 1: look at which variable is larger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09620ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"attacker\" variable says whether a given pokemon has higher attack value than HP\n",
    "pk['attacker'] = pk['Attack'] > pk['HP']\n",
    "\n",
    "pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43be39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot this variable across our generations\n",
    "sns.countplot(data = pk,\n",
    "              x = 'Generation',\n",
    "              hue = 'attacker'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a6a9e",
   "metadata": {},
   "source": [
    "***However, there's one challenge with this strategy.***\n",
    "\n",
    "If many pokemon have higher `Attack` than `HP` values, we can't always tell whether a pokemon has a greater *advantage* when attacking or withstanding an opponent by just looking at which value is higher. \n",
    "\n",
    "To see this, take a look at the distribution of `HP` and `Attack` variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249edbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the graph below, it's easiest to switch to tidy data!\n",
    "pk_tidy = pk.melt(\n",
    "    id_vars = [\"#\", \"Name\", \"Type 1\", \"Type 2\", \"Generation\", \"Legendary\", \"attacker\"]\n",
    ")\n",
    "pk_tidy\n",
    "\n",
    "\n",
    "sns.histplot(\n",
    "    data = pk_tidy[pk_tidy['variable'].isin([\"HP\", \"Attack\"])],\n",
    "    x = \"value\",\n",
    "    hue = \"variable\",\n",
    "    kde = True,\n",
    "    bins = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba3df1",
   "metadata": {},
   "source": [
    "In the graph above, the `Attack` distribution is shifted right and seems more spread out than the `HP` distribution, so most pokemon will likely have higher `Attack` points.\n",
    "\n",
    "What we really want to know might be something like: *relative to the competition, does each pokemon have a more impressive `Attack` or `HP` value?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f29a7",
   "metadata": {},
   "source": [
    "## Solution: when comparing across (normal) distributions, try z-scores!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd005b16",
   "metadata": {},
   "source": [
    "**What is a z-score?** \n",
    "\n",
    "A z-score for a given observation $x$ is the *number of standard deviations away from the mean* it is.\n",
    "\n",
    "$Z = \\dfrac{x - \\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ccecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pre-compute the mean and standard deviation of each distribution in our data (Attack and HP)\n",
    "\n",
    "mean_attack = pk['Attack'].mean() # 79\n",
    "mean_hp = pk['HP'].mean() # 69\n",
    "\n",
    "sd_attack = pk['Attack'].std() # 32.5\n",
    "sd_hp = pk['HP'].std() # 25.5\n",
    "\n",
    "# Note that these are fairly different in roughly the way we described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fb552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's evaluate the z score for each pokemon's Attack and HP values\n",
    "\n",
    "pk['attack_z'] = (pk['Attack'] - mean_attack) / sd_attack\n",
    "pk['hp_z'] = (pk['HP'] - mean_hp) / sd_hp\n",
    "\n",
    "pk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a417e",
   "metadata": {},
   "source": [
    "What do z-score distributions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data = pk, x = 'attack_z', color = 'red', alpha = 0.5)\n",
    "sns.kdeplot(data = pk, x = 'hp_z', color = 'green', alpha = 0.5)\n",
    "\n",
    "plt.xlabel(\"Z score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9934455",
   "metadata": {},
   "source": [
    "These are much more comparable!\n",
    "\n",
    "Now, we can ask which pokemon have a higher *z-scored* `Attack` relative to their *z-scored* `HP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk['z_attacker'] = pk['attack_z'] > pk['hp_z']\n",
    "\n",
    "pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5851a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot this variable across our generations\n",
    "sns.countplot(data = pk,\n",
    "              x = 'Generation',\n",
    "              hue = 'z_attacker'\n",
    "             )\n",
    "\n",
    "# Note it's a little less dramatic than our previous plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca0a93",
   "metadata": {},
   "source": [
    "This plot provides a little more balanced picture than our previous one. \n",
    "\n",
    "We can also use the z-scores to compare each pokemon's `Attack` and `HP` in a more fine-grained way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a94273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see which pokemon have the largest difference (in standard deviation units) between their `Attack` and `HP`\n",
    "pk['attack_diff_normalized'] = pk['attack_z'] - pk['hp_z']\n",
    "\n",
    "pk.nlargest(10, 'attack_diff_normalized')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7217fdd",
   "metadata": {},
   "source": [
    "We can plot this distribution and use it to evaluate the relative strength of a given pokemon's `Attack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31113c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.kdeplot(data = pk,\n",
    "            x = 'attack_diff_normalized'\n",
    "           )\n",
    "\n",
    "\n",
    "g.axvline(pk[pk['Name'] == 'Shedinja']['attack_diff_normalized'].iloc[0], # value to draw the line at\n",
    "            color = 'red', # color\n",
    "            ls = '--' # `linestyle`: '-', ':'\n",
    "           )\n",
    "\n",
    "g.text(3.25, 0.3, \"Shedinja\")\n",
    "\n",
    "g.set_xlim(-5, 5)\n",
    "g.set_title(\"Distribution of differences in Attack and HP z-scores\")\n",
    "g.set_xlabel(\"Normalized Attack - HP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf848d",
   "metadata": {},
   "source": [
    "## Z-scores: Summary\n",
    "\n",
    "- Sometimes for analysis purposes, you'll want to compare variables that are measured on different scales or show differences in the underlying distribution (ex. how to compare SAT and ACT scores?)\n",
    "\n",
    "- To make these comparisons, it's often easier to convert the data to a similar scale for comparison.\n",
    "\n",
    "- A z-score converts each data point to a *number of standard deviations above or below the mean*, which means you can more easily compare two scores that are otherwise very different or use these scores as the basis for regression or other analyses.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
  },
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
